## Research  At  UCI-ISURF

Donghak Park(Dankook.univ)
Donghyeon Choi(Kookmin.univ)
Woolim Cho(Sungkyunkwan.Univ)
##
## Security Implications of Compound Neural Network for Self-Driving Cars

## Mentor : Prof.Sang-Woo Jun

## Abstract

***In self-driving cars, deep learning is used to classify objects and determine actions, which
are the basic and important parts of autonomous driving. However, applying deep
learning to self-driving cars has two critical problems. First, deep learning models require
a lot of energy. It has been shown that the power consumption of deep-learning 
platforms has a significant impact on the driving range of autonomous vehicles, for both
electric and gasoline-powered cars. Second, deep learning models often have major
vulnerabilities which attackers can use to deceive the model. Attackers can use
“adversarial attacks,” where they create perturbed images from the originals which are
similar to human eyes, but models misclassify as another type of image. This may cause
serious physical and financial damage when using self-driving cars, because it may cause
the vehicle to operate abnormally. To solve these problems at the same time, we verified
existing research and applied those methods to a self-driving car simulator. Our major
methods of making robust and lightweight deep learning model are pruning and
quantization. In our experiment, we found that an 80% pruned model can be as robust
as an original model without losing accuracy, even against adversarial training. Also, we
found that quantization can compress the model by four times without losing accuracy.
These results show that we can make a robust and lightweight model to solve the two
problems simultaneously. In addition, we conducted an experiment to validate these
strategies in a real environment by using a self-driving car simulator “Apollo.”***
